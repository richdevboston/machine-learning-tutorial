{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-Up - MultiLayer Perceptron Classifier\n",
    "In this excercise we will go through scikit-learn high level modeling, as well as TensorFlow computational model. We will go through TensorFlow advanced modeling in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "As a step before running the training and machine learning model, we need to load the data. We will use `sklearn.datasets` to get a sample dataset. [Check this link for details](http://scikit-learn.org/stable/datasets/).\n",
    "The data should have two parts:\n",
    "- `X` - array-like data with `shape = (n_samples, n_features)`. That means the input array has to have `n_samples` rows and `n_features` columns.\n",
    "- `y` - array-like true labels list with `shape = (n_samples, 1)`, which means it has to have the same number of elements as the number of rows in the `X`. *Note: the shape of `y` could be `(n_samples, n_outputs)`*\n",
    "\n",
    "We will use `sklearn.datasets` for `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab --no-import-all inline\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split # To get the test data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## 1. Load the data\n",
    "X, y = make_circles(n_samples=1000, noise=0.05)\n",
    "\n",
    "## 1.1 Preprocess and split the data\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "## 1.2 Prepare some more data\n",
    "## The {xx, yy} are used to create decision boundaries for demo purposes later\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .02), np.arange(y_min, y_max, .02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data to use with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (800, 1) and (800,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-22a6174a3ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# mlp.fit(input_fn=lambda: input_fn(training_set), steps=5000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    433\u001b[0m     result = self._estimator.fit(x=x, y=y, input_fn=input_fn, steps=steps,\n\u001b[1;32m    434\u001b[0m                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                                  max_steps=max_steps)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmonitors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    331\u001b[0m                              \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                              \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                              max_steps=max_steps)\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\u001b[0m\n\u001b[1;32m    660\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m       \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m       \u001b[0;31m# Add default monitors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_get_train_ops\u001b[0;34m(self, features, targets)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0mTuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, targets, mode)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'mode'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'params'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.pyc\u001b[0m in \u001b[0;36m_dnn_classifier_model_fn\u001b[0;34m(features, targets, mode, params)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     loss = loss_fn(logits, targets,\n\u001b[0;32m--> 258\u001b[0;31m                    weight=_get_weight_tensor(features, weight_column_name))\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     train_ops = [optimizers.optimize_loss(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.pyc\u001b[0m in \u001b[0;36msigmoid_cross_entropy\u001b[0;34m(logits, multi_class_labels, weight, label_smoothing, scope)\u001b[0m\n\u001b[1;32m    327\u001b[0m   with ops.name_scope(scope, \"sigmoid_cross_entropy_loss\",\n\u001b[1;32m    328\u001b[0m                       [logits, multi_class_labels]):\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mmulti_class_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \"\"\"\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (800, 1) and (800,) are incompatible"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "COLUMNS = ['X'+str(idx+1) for idx in range(np.shape(X)[1])] + ['y']\n",
    "FEATURES = COLUMNS[:-1]\n",
    "LABEL = COLUMNS[-1]\n",
    "\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\n",
    "training_set = {'X'+str(idx+1): np.array(X_train[:, idx]) for idx in range(len(FEATURES))}\n",
    "training_set[LABEL] = np.array(y_train)\n",
    "\n",
    "mlp = tf.contrib.learn.DNNClassifier(feature_columns=feature_cols, hidden_units=[10, 10])\n",
    "\n",
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k]) for k in FEATURES}\n",
    "    labels = tf.constant(data_set[LABEL])\n",
    "    return feature_cols, labels\n",
    "                                 \n",
    "\n",
    "# mlp.fit(input_fn=lambda: input_fn(training_set), steps=5000)\n",
    "mlp.fit(input_fn=lambda: input_fn(training_set), steps=5000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Learn Implementation Flow\n",
    "`scikit-learn` Python package provides a collection of high-level calls to various machine learning algorithms. The beauty of this library is in its simplicity due to high level of abstraction.\n",
    "The library is not suited well for low level modeling, and one should use `SciPy` and `NumPy` for low-level design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Choose a model](http://scikit-learn.org/stable/tutorial/machine_learning_map/)\n",
    "Once you choose a model, you will have to instantiate it using the right arguments. We will discuss the parameters of the machine learning models in the later notebooks. For the current example we have to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(6,), \n",
    "    activation='relu',\n",
    "    max_iter=2000,\n",
    "    tol=1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the chosen model using `.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Predict new values using `.predict()`.\n",
    "Or you can get the probabilities of different labels using `.predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = mlp.predict(X_train)\n",
    "print (\"Train accuracy is {0:.2%}\".format(1. - np.mean(np.abs(y_hat - y_train))))\n",
    "y_hat = mlp.predict(X_test)\n",
    "print (\"Test accuracy is {0:.2%}\".format(1. - np.mean(np.abs(y_hat - y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Get the accuracy of the model using `.score()`\n",
    "If you just need the accuracy, you don't need to compute it yourself, and just use the `.score()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_score = mlp.score(X_train, y_train)\n",
    "test_score = mlp.score(X_test, y_test)\n",
    "print (\"Train accuracy is {0:.2%}\".format(train_score))\n",
    "print (\"Test accuracy is {0:.2%}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the MLP using \"Circles\" synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "## Specify the colormap:\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "if hasattr(mlp, \"decision_function\"):\n",
    "    Z = mlp.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "else:\n",
    "    Z = mlp.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z = Z.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "## Plot the test values\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n",
    "\n",
    "## Figure parmeters\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "## Title and score report\n",
    "ax.set_title('MLP circles')\n",
    "ax.text(xx.max() - .3, yy.min() + .3, ('{0:.2%}'.format(test_score)),\n",
    "                size=15, horizontalalignment='right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Neuron Visualization\n",
    "We can also visualize the outputs of individual neurons, as an example, let us see what the neurons of the hidden layer really represent. In order to do that, we will use `{xx, yy}` as an input. Note that different activation functions could be used! Also, the outputs of the hidden layers are supposed to be combined in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Step 1: Compute the outputs of the hidden layer\n",
    "hidden_layer_out = np.dot(np.c_[xx.ravel(), yy.ravel()], mlp.coefs_[-2])\n",
    "coef_1 = np.diag(mlp.coefs_[-1][:,0])\n",
    "y_hidden = np.dot(hidden_layer_out, coef_1)\n",
    "\n",
    "idx = 1\n",
    "for y_neuron in y_hidden.T:\n",
    "    y_neuron = y_neuron.reshape(xx.shape)\n",
    "    ax = plt.subplot(2,3,idx)\n",
    "    ax.contourf(xx, yy, y_neuron, cmap=cm, alpha=.8)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(\"Hidden layer %d\"%idx)\n",
    "    idx += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
